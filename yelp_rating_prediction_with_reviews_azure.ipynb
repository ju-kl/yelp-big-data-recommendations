{"nbformat_minor": 4, "cells": [{"execution_count": 18, "cell_type": "code", "source": "# basics\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# nlp\n#from nltk.corpus import stopwords\n\n# spark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import UserDefinedFunction\n\n# spark ML\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, CountVectorizer, Word2Vec\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator", "outputs": [{"output_type": "stream", "name": "stdout", "text": "/usr/bin/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')"}], "metadata": {"cell_status": {"execute_time": {"duration": 17317.344970703125, "end_time": 1597240216555.845}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 3, "cell_type": "code", "source": "# start spark session (from https://nlp.johnsnowlabs.com/docs/en/install#databricks) & script Ashish\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n    .appName(\"Spark NLP\")\\\n    .master(\"local[8]\")\\\n    .config(\"spark.driver.memory\",\"4g\")\\\n    .config(\"spark.driver.maxResultSize\", \"0\") \\\n    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.4\")\\\n    .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\\\n    .getOrCreate()", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 24602.14697265625, "end_time": 1597237074222.221}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### Big Data Platforms\n\n**Goal of this notebook:** Build a system that recommends a rating based on the review written by the user using databricks.\n\n**Resources used:**\n- Installations:\n  - https://www.youtube.com/watch?v=TNX_GShSyHc\n  - https://johnsnowlabs.github.io/spark-nlp-workshop/databricks/index.html#Getting%20Started.html\n\n- NLP:\n  - https://towardsdatascience.com/natural-language-processing-in-apache-spark-using-nltk-part-1-2-58c68824f660\n  - https://towardsdatascience.com/natural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba\n  - https://medium.com/analytics-vidhya/nlp-preprocessing-pipeline-what-when-why-2fc808899d1f\n  - https://www.analyticsvidhya.com/blog/2020/07/build-text-categorization-model-with-spark-nlp/", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"source": "### 1. Load data from storage container", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 13, "cell_type": "code", "source": "# define location variables\nFILE_NAME = \"review_subset.json\"\n\n# load data\nreview = spark.read.json(\"wasb:///\" + str(FILE_NAME))", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 15318.072021484375, "end_time": 1597240145863.458}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 14, "cell_type": "code", "source": "# print schema\nreview.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- label: double (nullable = true)\n |-- text: string (nullable = true)"}], "metadata": {"cell_status": {"execute_time": {"duration": 225.833984375, "end_time": 1597240146099.105}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 16, "cell_type": "code", "source": "# select stars and text for now\n#dat = review.select(\"stars\", \"text\")\ndat = review\n\n# print length of data\nprint(\"The dataset has {} observations.\".format(dat.count()))\n\n# rename text col to label\n#dat = dat.withColumnRenamed(\"stars\",\"label\")\n\n# display\ndat.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "The dataset has 400430 observations.\n+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|  1.0|\"Beware  of the m...|\n|  1.0|$99 dollar specia...|\n|  1.0|(This is for the ...|\n|  1.0|***************bu...|\n|  1.0|***DO NOT TAKE YO...|\n+-----+--------------------+\nonly showing top 5 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 5713.152099609375, "end_time": 1597240191091.608}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### 2. Feature engineering", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 19, "cell_type": "code", "source": "# initialize tokenizer\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n\n# initialize StopWordsRemover\nstopword_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n\n# initialize hashingTF\nhashingTF = HashingTF(inputCol=stopword_remover.getOutputCol(), outputCol=\"features\")\n\n# build pipeline\npipeline_1 = Pipeline(stages=[tokenizer, stopword_remover, hashingTF])\n\n# fit pipeline to data\ndat_encoded_1 = pipeline_1.fit(dat).transform(dat)\n\n# show\ndat_encoded_1.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+--------------------+--------------------+--------------------+\n|label|                text|               words|            filtered|            features|\n+-----+--------------------+--------------------+--------------------+--------------------+\n|  1.0|\"Beware  of the m...|[\"beware, , of, t...|[\"beware, , man, ...|(262144,[2281,205...|\n|  1.0|$99 dollar specia...|[$99, dollar, spe...|[$99, dollar, spe...|(262144,[781,1789...|\n|  1.0|(This is for the ...|[(this, is, for, ...|[(this, psychic, ...|(262144,[14,3068,...|\n|  1.0|***************bu...|[***************b...|[***************b...|(262144,[5937,892...|\n|  1.0|***DO NOT TAKE YO...|[***do, not, take...|[***do, take, car...|(262144,[7473,828...|\n+-----+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 3254.14892578125, "end_time": 1597240226433.871}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### 3. Model building", "cell_type": "markdown", "metadata": {}}, {"execution_count": 20, "cell_type": "code", "source": "# train/test split\ntrain_df, test_df = dat_encoded_1.randomSplit([.8,.2],seed=3)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 226.64111328125, "end_time": 1597240229850.608}}, "editable": true, "collapsed": true, "deletable": true}}, {"execution_count": 21, "cell_type": "code", "source": "# initialize logistic regression model\nlr = LogisticRegression(maxIter=10, regParam=0.01)\n\n# make prediction\nlrm = lr.fit(train_df)\n\n# create predictions df\npredictions = lrm.transform(test_df)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 41885.98388671875, "end_time": 1597240272615.019}}, "collapsed": true}}, {"execution_count": 22, "cell_type": "code", "source": "# initialize evaluator\nevaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n\n# evaluate predictions\nprint(evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"}))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.942720716442"}], "metadata": {"cell_status": {"execute_time": {"duration": 15310.554931640625, "end_time": 1597240287936.109}}, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}