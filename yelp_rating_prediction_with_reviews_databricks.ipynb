{"cells":[{"cell_type":"code","source":["# basics\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# mounting to aws\nimport urllib\n\n# spark\nfrom pyspark.sql import SparkSession\n\n# spark ML\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, IDF, CountVectorizer, Word2Vec\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# spark nlp\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom sparknlp.pretrained import PretrainedPipeline\nimport sparknlp"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# spark context\nspark.sparkContext"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.172.226.5:42739\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]}}],"execution_count":2},{"cell_type":"code","source":["# start spark session (from https://nlp.johnsnowlabs.com/docs/en/install#databricks) & script Ashish\nspark = SparkSession.builder \\\n    .appName(\"Spark NLP\")\\\n    .master(\"local[8]\")\\\n    .config(\"spark.driver.memory\",\"4g\")\\\n    .config(\"spark.driver.maxResultSize\", \"0\") \\\n    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.5\")\\\n    .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\\\n    .getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### Big Data Platforms\n\n**Goal of this notebook:** Build a system that recommends a rating based on the review written by the user using databricks.\n\n**Resources used:**\n- Installations:\n  - https://www.youtube.com/watch?v=TNX_GShSyHc\n  - https://johnsnowlabs.github.io/spark-nlp-workshop/databricks/index.html#Getting%20Started.html\n\n- NLP:\n  - https://towardsdatascience.com/natural-language-processing-in-apache-spark-using-nltk-part-1-2-58c68824f660\n  - https://towardsdatascience.com/natural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba\n  - https://medium.com/analytics-vidhya/nlp-preprocessing-pipeline-what-when-why-2fc808899d1f\n  - https://www.analyticsvidhya.com/blog/2020/07/build-text-categorization-model-with-spark-nlp/"],"metadata":{}},{"cell_type":"markdown","source":["### Step 1: Connect to S3 bucket and load data"],"metadata":{}},{"cell_type":"code","source":["# retrieve aws credentials from table\naws_credentials = spark.table('databricks_spark_accesskeys_1_csv') \n\n# mount notebook to S3 bucket\nACCESS_KEY = aws_credentials.select(\"Access key ID\").collect()[0][0]\nSECRET_KEY = aws_credentials.select(\"Secret access key\").collect()[0][0]\nENCODED_SECRET_KEY = urllib.parse.quote(SECRET_KEY, \"\")\nAWS_BUCKET_NAME = \"big-data-class-final-project\"\nMOUNT_NAME = \"s3_v9\"\ndbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n\n# display content of S3 bucket\ndisplay(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/s3_v9/_metadata</td><td>_metadata</td><td>0</td></tr><tr><td>dbfs:/mnt/s3_v9/bootstrap_action.sh</td><td>bootstrap_action.sh</td><td>112</td></tr><tr><td>dbfs:/mnt/s3_v9/e-CXPSZT7I8V76S2JSSVTHOPBE/</td><td>e-CXPSZT7I8V76S2JSSVTHOPBE/</td><td>0</td></tr><tr><td>dbfs:/mnt/s3_v9/j-16PDN1URFLEDB/</td><td>j-16PDN1URFLEDB/</td><td>0</td></tr><tr><td>dbfs:/mnt/s3_v9/j-1QDUUJ03UG2UB/</td><td>j-1QDUUJ03UG2UB/</td><td>0</td></tr><tr><td>dbfs:/mnt/s3_v9/j-565CHQX5IPNM/</td><td>j-565CHQX5IPNM/</td><td>0</td></tr><tr><td>dbfs:/mnt/s3_v9/j-QLM4SQGJ2LK8/</td><td>j-QLM4SQGJ2LK8/</td><td>0</td></tr><tr><td>dbfs:/mnt/s3_v9/review_subset.json</td><td>review_subset.json</td><td>248796774</td></tr><tr><td>dbfs:/mnt/s3_v9/review_subset_spark_nlp_hashingTF_model_pipeline/</td><td>review_subset_spark_nlp_hashingTF_model_pipeline/</td><td>0</td></tr><tr><td>dbfs:/mnt/s3_v9/yelp_academic_dataset_review.json</td><td>yelp_academic_dataset_review.json</td><td>6325565224</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# define location variables\n#FILE_NAME = \"yelp_academic_dataset_review.json\"\nFILE_NAME = \"review_subset.json\"\n\n# load data\nreview = spark.read.json(\"dbfs:/mnt/\" + str(MOUNT_NAME) + \"/\" + str(FILE_NAME))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# print schema\nreview.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- label: double (nullable = true)\n-- text: string (nullable = true)\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# select stars and text for now\n#dat = review.select(\"stars\", \"text\")\ndat = review\n\n# print length of data\nprint(\"The dataset has {} observations.\".format(dat.count()))\n\n# rename text col to label\n#dat = dat.withColumnRenamed(\"stars\",\"label\")\n\n# display\ndat.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The dataset has 400430 observations.\n+-----+--------------------+\nlabel|                text|\n+-----+--------------------+\n  1.0|&#34;Beware  of the m...|\n  1.0|$99 dollar specia...|\n  1.0|(This is for the ...|\n  1.0|***************bu...|\n  1.0|***DO NOT TAKE YO...|\n+-----+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["# spilt into train and test\n(dat_train, dat_test) = dat.randomSplit([.8,.2],seed=3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# display train\ndat_train.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nlabel|                text|\n+-----+--------------------+\n  1.0|&#34;Beware  of the m...|\n  1.0|&#34;Don&#39;t judge a bo...|\n  1.0|&#34;Happy Halloween&#34;...|\n  1.0|&#34;How much is a Cl...|\n  1.0|&#34;ICKY- Ban&#34; is a ...|\n+-----+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### 2. Pipelines: Preprocessing - feature engineering - model training"],"metadata":{}},{"cell_type":"markdown","source":["**Pipeline 1 : HashingTF**"],"metadata":{}},{"cell_type":"code","source":["# assemble document\ndocument_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n\n# convert document to array of tokens\ntokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n\n# clean tokens \nnormalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normalized\")\n\n# lemmatize\nlemmatizer = LemmatizerModel.pretrained().setInputCols([\"normalized\"]).setOutputCol(\"lemma\")\n\n# remove stopwords\nstopwords_cleaner = StopWordsCleaner().setInputCols(\"lemma\").setOutputCol(\"cleanTokens\").setCaseSensitive(False)\n\n# stems tokens to bring it to root form\nstemmer = Stemmer().setInputCols([\"cleanTokens\"]).setOutputCol(\"stem\")\n\n# convert custom document structure to array of tokens.\nfinisher = Finisher().setInputCols([\"stem\"]).setOutputCols([\"token_features\"]).setOutputAsArray(True).setCleanAnnotations(False)\n\n# initialize hashingTF\nhashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"features\", numFeatures=1000)\n\n# initialize logistic regression\nlr = LogisticRegression(maxIter=10, regParam=0.01)\n\n# preprocessing pipeline\npipeline_1 = Pipeline(stages=[document_assembler, \n                              tokenizer,\n                              normalizer, \n                              lemmatizer,\n                              stopwords_cleaner, \n                              stemmer, \n                              finisher,\n                              hashingTF,\n                              lr])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">lemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["# fit the pipeline on training data\npipeline_model_1 = pipeline_1.fit(dat_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["# perform predictions on test data\npredictions_1 =  pipeline_model_1.transform(dat_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["# initialize evaluator\nevaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n\n# evaluate predictions\nprint(evaluator.evaluate(predictions_1, {evaluator.metricName: \"rmse\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1.1677522921609929\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# save pipeline model\nMODEL_NAME = \"review_subset_spark_nlp_hashingTF_model_pipeline\"\npipeline_model_1.save(\"dbfs:/mnt/\" + str(MOUNT_NAME) + \"/\" + str(MODEL_NAME))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18}],"metadata":{"name":"rating_prediction_with_reviews_databricks","notebookId":3400625034569016},"nbformat":4,"nbformat_minor":0}
