{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip Data Exploration\n",
    "**Objective of this notebook**: Load Yelp Tip data into and explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data as pandas df and convert it to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>compliment_count</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UYX5zL_Xj9WEc_Wp-FrqHw</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-26 18:20:08</td>\n",
       "      <td>Here for a quick mtg</td>\n",
       "      <td>hf27xTME3EiCp6NL6VtWZQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ch3HkwQYv1YKw_FO06vBWA</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-15 22:26:45</td>\n",
       "      <td>Cucumber strawberry refresher</td>\n",
       "      <td>uEvusDwoSymbJJ0auR3muQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDoT-MgxGRiYqCmi0bG10g</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-18 22:03:42</td>\n",
       "      <td>Very nice good service good food</td>\n",
       "      <td>AY-laIws3S7YXNl_f_D6rQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OHXnDV01gLokiX1ELaQufA</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-06 01:10:34</td>\n",
       "      <td>It's a small place. The staff is friendly.</td>\n",
       "      <td>Ue_7yUlkEbX4AhnYdUfL7g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GMrwDXRlAZU2zj5nH6l4vQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-04-08 18:12:01</td>\n",
       "      <td>8 sandwiches, $24 total...what a bargain!!! An...</td>\n",
       "      <td>LltbT_fUMqZ-ZJP-vJ84IQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  compliment_count                date  \\\n",
       "0  UYX5zL_Xj9WEc_Wp-FrqHw                 0 2013-11-26 18:20:08   \n",
       "1  Ch3HkwQYv1YKw_FO06vBWA                 0 2014-06-15 22:26:45   \n",
       "2  rDoT-MgxGRiYqCmi0bG10g                 0 2016-07-18 22:03:42   \n",
       "3  OHXnDV01gLokiX1ELaQufA                 0 2014-06-06 01:10:34   \n",
       "4  GMrwDXRlAZU2zj5nH6l4vQ                 0 2011-04-08 18:12:01   \n",
       "\n",
       "                                                text                 user_id  \n",
       "0                               Here for a quick mtg  hf27xTME3EiCp6NL6VtWZQ  \n",
       "1                      Cucumber strawberry refresher  uEvusDwoSymbJJ0auR3muQ  \n",
       "2                   Very nice good service good food  AY-laIws3S7YXNl_f_D6rQ  \n",
       "3         It's a small place. The staff is friendly.  Ue_7yUlkEbX4AhnYdUfL7g  \n",
       "4  8 sandwiches, $24 total...what a bargain!!! An...  LltbT_fUMqZ-ZJP-vJ84IQ  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert json into csv file\n",
    "tip_data = pd.read_json(\"archive/yelp_academic_dataset_tip.json\", lines=True)\n",
    "\n",
    "# save tip_data as csv\n",
    "tip_data.to_csv(\"tip/yelp_academic_dataset_tip.csv\", index=False)\n",
    "\n",
    "# display\n",
    "tip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.yarn.jars',\n",
       "  'local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/jars/*,local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/hive/*'),\n",
       " ('spark.yarn.appMasterEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.sql.queryExecutionListeners',\n",
       "  'com.cloudera.spark.lineage.NavigatorQueryListener'),\n",
       " ('spark.lineage.log.dir', '/var/log/spark/lineage'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'md01.rcc.local,md02.rcc.local'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip:/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/pyspark.zip'),\n",
       " ('spark.yarn.historyServer.address', 'http://hd01.rcc.local:18088'),\n",
       " ('spark.driver.appUIAddress', 'http://md01.rcc.local:4042'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.network.crypto.enabled', 'false'),\n",
       " ('spark.executorEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.ui.enabled', 'true'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.app.id', 'application_1577383759214_8933'),\n",
       " ('spark.dynamicAllocation.schedulerBacklogTimeout', '1'),\n",
       " ('spark.yarn.config.gatewayPath', '/opt/cloudera/parcels'),\n",
       " ('spark.extraListeners', 'com.cloudera.spark.lineage.NavigatorAppListener'),\n",
       " ('spark.port.maxRetries', '60'),\n",
       " ('spark.sql.warehouse.dir', '/user/hive/warehouse'),\n",
       " ('spark.app.name', 'Spark Updated Conf'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.log.persistToDfs.enabled', 'true'),\n",
       " ('spark.yarn.config.replacementPath', '{{HADOOP_COMMON_HOME}}/../../..'),\n",
       " ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.driver.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.driver.port', '38697'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.ui.killEnabled', 'true'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.eventLog.dir', 'hdfs://nameservice1/user/spark/applicationHistory'),\n",
       " ('spark.dynamicAllocation.executorIdleTimeout', '60'),\n",
       " ('spark.executor.cores', '4'),\n",
       " ('spark.io.encryption.enabled', 'false'),\n",
       " ('spark.authenticate', 'false'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1577383759214_8933'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS',\n",
       "  'md01.rcc.local:8088,md02.rcc.local:8088'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.yarn.historyServer.allowTracking', 'true'),\n",
       " ('spark.yarn.appMasterEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.shuffle.service.port', '7337'),\n",
       " ('spark.lineage.enabled', 'true'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://md01.rcc.local:8088/proxy/application_1577383759214_8933,http://md02.rcc.local:8088/proxy/application_1577383759214_8933'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.driver.host', 'md01.rcc.local'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.yarn.am.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.dynamicAllocation.minExecutors', '0'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.log.dfsDir', '/user/spark/driverLogs')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start Spark session\n",
    "spark = SparkSession.builder.appName('yelp_tip').getOrCreate()\n",
    "\n",
    "# change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'), \n",
    "                                        ('spark.app.name', 'Spark Updated Conf'), \n",
    "                                        ('spark.executor.cores', '4'), \n",
    "                                        ('spark.cores.max', '4'), \n",
    "                                        ('spark.driver.memory','4g')])\n",
    "\n",
    "# print spark configuration settings\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into spark from hdfs\n",
    "dat = spark.read.csv(\"/user/kleindiek/final_project/tip/yelp_academic_dataset_tip.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('business_id', 'string'),\n",
       " ('compliment_count', 'string'),\n",
       " ('date', 'string'),\n",
       " ('text', 'string'),\n",
       " ('user_id', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate data types\n",
    "dat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# investigate schema\n",
    "dat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------------------+--------------------+--------------------+\n",
      "|         business_id|compliment_count|               date|                text|             user_id|\n",
      "+--------------------+----------------+-------------------+--------------------+--------------------+\n",
      "|UYX5zL_Xj9WEc_Wp-...|               0|2013-11-26 18:20:08|Here for a quick mtg|hf27xTME3EiCp6NL6...|\n",
      "|Ch3HkwQYv1YKw_FO0...|               0|2014-06-15 22:26:45|Cucumber strawber...|uEvusDwoSymbJJ0au...|\n",
      "|rDoT-MgxGRiYqCmi0...|               0|2016-07-18 22:03:42|Very nice good se...|AY-laIws3S7YXNl_f...|\n",
      "|OHXnDV01gLokiX1EL...|               0|2014-06-06 01:10:34|It's a small plac...|Ue_7yUlkEbX4AhnYd...|\n",
      "|GMrwDXRlAZU2zj5nH...|               0|2011-04-08 18:12:01|8 sandwiches, $24...|LltbT_fUMqZ-ZJP-v...|\n",
      "|ALwAlxItASeEs2vYA...|               0|2015-05-20 20:17:38|Great ramen! Not ...|HHNBqfbDR8b1iq-QG...|\n",
      "|d_L-rfS1vT3JMzgCU...|               0|2014-09-01 01:23:48|Cochinita Pibil w...|r0j4IpUbcdC1-HfoM...|\n",
      "|5FIOXmUE3qMviX9Ga...|               0|2010-01-30 02:03:16|Get a tsoynami fo...|gxVQZJVeKBUk7jEhS...|\n",
      "|rcaPajgKOJC2vo_l3...|               0|2012-05-29 02:05:56|Kelly is an aweso...|2hdR7KYAmnCk2FjTn...|\n",
      "|hfBrethLHS9iXeBNR...|               0|2011-09-30 18:38:47|Check out the gre...|DsWg3leomfasGs3j0...|\n",
      "+--------------------+----------------+-------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show first 10 rows\n",
    "dat.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1363162.\n",
      "Number of unique businesses: 171010.\n",
      "Number of unique users: 362556.\n"
     ]
    }
   ],
   "source": [
    "# number of rows\n",
    "print(\"Number of rows: {}.\".format(dat.count()))\n",
    "\n",
    "# number of unique businesses\n",
    "print(\"Number of unique businesses: {}.\".format(dat.select(\"business_id\").distinct().count()))\n",
    "\n",
    "# number of unique users\n",
    "print(\"Number of unique users: {}.\".format(dat.select(\"user_id\").distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             user_id|count|\n",
      "+--------------------+-----+\n",
      "|                null|69231|\n",
      "|mkbx55W8B8aPLgDqe...| 2600|\n",
      "|CxDOIDnH8gp9KXzpB...| 1667|\n",
      "|0tvCcnfJnSs55iB6m...| 1589|\n",
      "|6ZC-0LfOAGwaFc5XP...| 1510|\n",
      "|eZfHm0qI8A_HfvXSc...| 1324|\n",
      "|O8eDScRAg6ae0l9Bc...| 1300|\n",
      "|8DGFWco9VeBAxjqsu...| 1179|\n",
      "|2EuPAGalYnP7eSxPg...| 1165|\n",
      "|WJKocp9RE0KatUwh3...| 1111|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# identify power users\n",
    "dat.groupby(\"user_id\").count().orderBy([\"count\"], ascending=[0]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         business_id|count|\n",
      "+--------------------+-----+\n",
      "|FaHADZARwnY4yvlvp...| 3679|\n",
      "|JmI9nslLD7KZqRr__...| 2494|\n",
      "|DkYS3arLOhA8si5uU...| 1530|\n",
      "|5LNZ67Yw9RD6nf4_U...| 1525|\n",
      "|K7lWdNUhCbcnEvI0N...| 1434|\n",
      "|hihud--QRriCYZw1z...| 1394|\n",
      "|RESDUcs7fIiihp38-...| 1386|\n",
      "|4JNXUYY8wbaaDmk3B...| 1185|\n",
      "|yfxDa8RFOvJPQh0rN...| 1154|\n",
      "|iCQpiavjjPzJ5_3gP...| 1145|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# identify power businesses\n",
    "dat.groupby(\"business_id\").count().orderBy([\"count\"], ascending=[0]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.37% of observations have a compliment_count > 0.\n"
     ]
    }
   ],
   "source": [
    "# filter tips with compliment > 0\n",
    "print(\"{:.2f}% of observations have a compliment_count > 0.\".format((dat.filter(dat.compliment_count > 0).count())/dat.count()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zzcMR3izHZRiWvJI02GtIA'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max compliment count\n",
    "dat.agg({\"compliment_count\": \"max\"}).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
